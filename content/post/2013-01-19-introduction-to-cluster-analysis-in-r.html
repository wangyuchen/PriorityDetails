---
title: Introduction to Cluster Analysis in R
author: Yuchen Wang
date: '2013-01-19'
slug: introduction-to-cluster-analysis-in-r
categories:
  - R
tags:
  - R Markdown
  - clustering
---



<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters).</p>
<p>Clustering can be applied to microarray data to identify groups of possibly co-regulated genes or spatial gene expression patterns.</p>
<p>In Anja von Heydebreck’s presentation <em>Clustering analysis for microarray data</em>, he introduced many clustering methods including K-means lusting, PAM and Hierarchical clustering. He also gave some R packages which implemented these jobs. I will try to summary cluster analysis methods in R using microarray datasets.</p>
</div>
<div id="sample-data" class="section level2">
<h2>Sample Data</h2>
<p>The bioconductor project has various packages for <a href="1">experimental data</a>. To install bioconductor packages, a special tool called <code>biocLite</code> is used. The demo data Golub is installed with the following command in R.</p>
<pre class="r"><code>source(&quot;http://bioconductor.org/biocLite.R&quot;)
biocLite(&quot;golubEsets&quot;)</code></pre>
<p>The Golub et al. (1999) data consist of 47 patients with acute lymphoblastic leukemia (ALL) and 25 patients with acute myeloid leukemia (AML). Each of the 72 patients had bone marrow samples obtained at the time of diagnosis. Furthermore, the observations have been assayed with Affymetrix Hgu6800 chips, resulting in 7129 gene expressions (Affymetrix probes).</p>
<p>As discussed in the Bioconductor manual, “ALL arises from two different types of lymphocytes (T-cell and B-cell)”, so we may wish to consider the data in terms of three classes: AML, ALL-T, and ALL-B. We provide the option to consider the data as two or three classes. Also, the Golub data set is often seen in two forms. In one case, the data are partitioned into a training and a test data set: we provide these as <code>Golub_Train</code> and <code>Golub_Test</code>, respectively. In the other case, the training and the test data sets are combined into one data set: we have named this golub.</p>
<p>The Golub data set is possibly the most widely studied and cited microarray data set.</p>
<pre class="r"><code># load require package and datasets
library(golubEsets)
data(Golub_Merge)
golub &lt;- data.frame(Golub_Merge)[1:7129]
# calculate variance and rearrange columns by variance decreasingly
golub.rearrange &lt;- golub[ , order(apply(golub, 2, var), decreasing=T)]
golub &lt;- golub.rearrange[, 1:150]</code></pre>
<p>Then <code>golub</code> is the new dataset for use with all the following clustering methods.</p>
</div>
<div id="partitioning" class="section level2">
<h2>Partitioning</h2>
<p>The partitioning methods generally result in a set of M clusters, each object belonging to one cluster. Each cluster may be represented by a centroid or a cluster representative. If the number of the clusters is large, the centroids can be further clustered to produces hierarchy within a dataset.</p>
<div id="k-means-clustering" class="section level3">
<h3>K-means Clustering</h3>
<p>R supports K-means Clustering by default. The <code>kmeans()</code> function can be used to do this and 4 algorithms are available. When using K-means Clustering, the number of clusters should be determined in advance. Here we set the number of clusters to be 8.</p>
<pre class="r"><code># K-Means Cluster Analysis
fit &lt;- kmeans(x=golub, 8)</code></pre>
<p>Result is stored in an S3 object of class <code>kmeans</code>. Information like cluster assignment and cluster centers can be extracted using the following commands.</p>
<pre class="r"><code>fit$cluster  # get cluster assignment
fit$centers  # get cluster center
# get cluster means
aggregate(golub, by=list(fit$cluster), FUN=mean)</code></pre>
</div>
<div id="partitioning-around-medoids" class="section level3">
<h3>Partitioning Around Medoids</h3>
<p>K-means clustering is based on Euclidean distance. PAM generalizes the idea and can be used with any distance measure. Just as in K-means clustering, PAM requires the number of clusters to be determined in advance. R recommands the <code>cluster</code> package (installed with R) for PAM. It implemented a pam object and summary methods.</p>
<pre class="r"><code>require(cluster) 
fit &lt;- pam(x=golub, k=8)</code></pre>
<p>The assignment and the medoids are still of interest.</p>
<pre class="r"><code>fit$clustering # get cluster assignment
fit$medoids # get coordinates of each medoid
# summary method
summary(fit)</code></pre>
</div>
</div>
<div id="hierarchical-agglomerative" class="section level2">
<h2>Hierarchical Agglomerative</h2>
<p>Hierarchical Clustering is a method of cluster analysis which seeks to build a hierarchy of clusters. Agglomerative is a “bottom up” approach: each observation starts in its own cluster, and pairs of clusters are merged as one moves up the hierarchy. R also supports it by default in <code>hclust()</code>, with the distance matrix can be calculated using one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski” distance.</p>
<pre class="r"><code># Ward Hierarchical Clustering
d &lt;- dist(golub, method = &quot;euclidean&quot;) # distance matrix
fit &lt;- hclust(d, method=&quot;ward&quot;) </code></pre>
<pre><code>## The &quot;ward&quot; method has been renamed to &quot;ward.D&quot;; note new &quot;ward.D2&quot;</code></pre>
<p>Hierarchical Clustering will be better understood in plots. R has special plot methods for plotting an object of class <code>hclust</code>.</p>
<pre class="r"><code>plot(fit)
groups &lt;- cutree(fit, k=8) # cut tree into 5 clusters
# draw dendogram with red borders around the 5 clusters 
rect.hclust(fit, k=8, border=&quot;red&quot;)</code></pre>
<p><img src="/post/2013-01-19-introduction-to-cluster-analysis-in-r_files/figure-html/unnamed-chunk-5-1.png" width="960" /></p>
</div>
<div id="visualization-of-similarity" class="section level2">
<h2>Visualization of Similarity</h2>
<p>As Heydebreck mentioned that a direct visualization is more informative. It’s useful when one wants to investigate a specific factor. Here we just inspect the correlation of the genes with the highest variance.</p>
<pre class="r"><code>library(corrplot)</code></pre>
<pre><code>## corrplot 0.84 loaded</code></pre>
<pre class="r"><code>corrplot(cor(golub.rearrange[ , 1:20]))</code></pre>
<p><img src="/post/2013-01-19-introduction-to-cluster-analysis-in-r_files/figure-html/unnamed-chunk-6-1.png" width="960" /></p>
</div>
<div id="conclusions" class="section level2">
<h2>Conclusions</h2>
<p>These are just basic some basic cluster analysis in R. R implemented several user-friendly functions to do cluster analysis. As you can see from the above example, R code are always simple and readable. Therefore, Clustering algorithms are easy to apply and they are useful for exploratory analysis.</p>
</div>
